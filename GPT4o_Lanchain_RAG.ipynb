{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai (from -r requirements.txt (line 1))\n",
      "  Obtaining dependency information for langchain_openai from https://files.pythonhosted.org/packages/95/ac/ec2eaa55a7eea519b17a7687e5bf1387dd313f41cf19750f9cfb96db44f9/langchain_openai-0.1.8-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain_core (from -r requirements.txt (line 2))\n",
      "  Obtaining dependency information for langchain_core from https://files.pythonhosted.org/packages/aa/e2/9d7ccae2e2b2983912d71eacf8626d7b5f186389cd82eaa2930896132feb/langchain_core-0.2.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.2.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.0.1)\n",
      "Collecting streamlit (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/0e/86/69fdac2ec6852304bda08e5af5b72dfa6e74dc0b3cef0d7c1e19994388ae/streamlit-1.35.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading streamlit-1.35.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain_community (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/a5/c9/7d5a501f96cb508bc55a00be5f7e38f6c7c9880b534b7e21a70a8e7ea277/langchain_community-0.2.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting langserve (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for langserve from https://files.pythonhosted.org/packages/97/92/ab9bc89750ee947b89e3c0b880ae39b24e05257f175c375bdfe963f02c35/langserve-0.2.1-py3-none-any.whl.metadata\n",
      "  Downloading langserve-0.2.1-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting fastapi (from -r requirements.txt (line 7))\n",
      "  Obtaining dependency information for fastapi from https://files.pythonhosted.org/packages/e6/33/de41e554e5a187d583906e10d53bfae5fd6c07e98cbf4fe5262bd37e739a/fastapi-0.111.0-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn (from -r requirements.txt (line 8))\n",
      "  Obtaining dependency information for uvicorn from https://files.pythonhosted.org/packages/2a/a1/d57e38417a8dabb22df02b6aebc209dc73485792e6c5620e501547133d0b/uvicorn-0.30.0-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.30.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting sse_starlette (from -r requirements.txt (line 9))\n",
      "  Obtaining dependency information for sse_starlette from https://files.pythonhosted.org/packages/15/51/faf3a6478876bfa30d28a9bfa60cf191fd79bfac79f7595a6d342e66c44a/sse_starlette-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading sse_starlette-2.1.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting bs4 (from -r requirements.txt (line 10))\n",
      "  Obtaining dependency information for bs4 from https://files.pythonhosted.org/packages/51/bb/bf7aab772a159614954d84aa832c129624ba6c32faa559dfb200a534e50b/bs4-0.0.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting pypdf (from -r requirements.txt (line 11))\n",
      "  Obtaining dependency information for pypdf from https://files.pythonhosted.org/packages/c9/d1/450b19bbdbb2c802f554312c62ce2a2c0d8744fe14735bc70ad2803578c7/pypdf-4.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting faiss-cpu (from -r requirements.txt (line 12))\n",
      "  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/d3/ad/63eb31be05c38445781caecbc6d3b9dec151012194b00573ba34f29d5cf5/faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting groq (from -r requirements.txt (line 13))\n",
      "  Obtaining dependency information for groq from https://files.pythonhosted.org/packages/15/e4/835f485c6b3268fbc52687481dd574d785b6500384b150196686d78f4cdf/groq-0.8.0-py3-none-any.whl.metadata\n",
      "  Downloading groq-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cassio (from -r requirements.txt (line 14))\n",
      "  Obtaining dependency information for cassio from https://files.pythonhosted.org/packages/4a/ad/8213b4de4ac492ebd61e4429b91e2b9a2ca8bba861b1dcfc8d8981e5e284/cassio-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading cassio-0.1.7-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 15)) (4.12.2)\n",
      "Collecting langchain-groq (from -r requirements.txt (line 16))\n",
      "  Obtaining dependency information for langchain-groq from https://files.pythonhosted.org/packages/b8/62/a9695a0d95f0554e156d05d7dd3777486e6ce9fa93ceb9030a6aeee8de07/langchain_groq-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading langchain_groq-0.1.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting wikipedia (from -r requirements.txt (line 17))\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting arxiv (from -r requirements.txt (line 18))\n",
      "  Obtaining dependency information for arxiv from https://files.pythonhosted.org/packages/99/16/532c2aa4bc83b2356820efd4d1f619e45178dc3a0dc0cde16fbccdc43fc1/arxiv-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading arxiv-2.1.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting langchainhub (from -r requirements.txt (line 19))\n",
      "  Obtaining dependency information for langchainhub from https://files.pythonhosted.org/packages/8f/24/10dd40be612a2e7225517a0c95edde5809e319c6bc4294d8bfbe18108beb/langchainhub-0.1.17-py3-none-any.whl.metadata\n",
      "  Downloading langchainhub-0.1.17-py3-none-any.whl.metadata (621 bytes)\n",
      "Collecting sentence_transformers (from -r requirements.txt (line 20))\n",
      "  Obtaining dependency information for sentence_transformers from https://files.pythonhosted.org/packages/f8/c4/99a9386808025d5a546576243bfd3b1eb669f978b8a0e05a1253eaf89bf0/sentence_transformers-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting PyPDF2 (from -r requirements.txt (line 21))\n",
      "  Obtaining dependency information for PyPDF2 from https://files.pythonhosted.org/packages/8e/5e/c86a5643653825d3c913719e788e41386bee415c2b87b4f955432f2de6b2/pypdf2-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langchain-objectbox (from -r requirements.txt (line 22))\n",
      "  Obtaining dependency information for langchain-objectbox from https://files.pythonhosted.org/packages/2d/27/fb79470372e8f23d079e9fa6b1c362835ad33ebb454b6a0e24a879747f0f/langchain_objectbox-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain_objectbox-0.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: pyopenssl in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 24)) (23.2.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 25)) (2.1.1)\n",
      "Collecting openai<2.0.0,>=1.26.0 (from langchain_openai->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for openai<2.0.0,>=1.26.0 from https://files.pythonhosted.org/packages/bd/51/e05017d7c2d7fac63583a3000833e43d137edf5613cb849a1bc3b03ac5ce/openai-1.30.4-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.30.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for tiktoken<1,>=0.7 from https://files.pythonhosted.org/packages/b1/10/c04b4ff592a5f46b28ebf4c2353f735c02ae7f0ce1b165d00748ced6467e/tiktoken-0.7.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from langchain_core->-r requirements.txt (line 2)) (6.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain_core->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_core->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for langsmith<0.2.0,>=0.1.0 from https://files.pythonhosted.org/packages/bf/47/5e218733516797e7dcd6f2f67efd458de99ce5181945753f3b9cd62bd40c/langsmith-0.1.63-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.1.63-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain_core->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain_core->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for pydantic<3,>=1 from https://files.pythonhosted.org/packages/6f/b9/ec44b1394957d5aa8d3a7c33f8304cd7670d10a43a286db56cec086346be/pydantic-2.7.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.7.2-py3-none-any.whl.metadata (108 kB)\n",
      "     ---------------------------------------- 0.0/108.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 108.5/108.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from langchain_core->-r requirements.txt (line 2)) (8.2.2)\n",
      "Collecting altair<6,>=4.0 (from streamlit->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for altair<6,>=4.0 from https://files.pythonhosted.org/packages/46/30/2118537233fa72c1d91a81f5908a7e843a6601ccc68b76838ebc4951505f/altair-5.3.0-py3-none-any.whl.metadata\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for blinker<2,>=1.0.0 from https://files.pythonhosted.org/packages/bb/2a/10164ed1f31196a2f7f3799368a821765c62851ead0e630ab52b8e14b4d0/blinker-1.8.2-py3-none-any.whl.metadata\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (8.0.4)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (1.24.3)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (1.5.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (9.4.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (11.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (13.7.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (4.10.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for gitpython!=3.1.19,<4,>=3.0.7 from https://files.pythonhosted.org/packages/e9/bd/cc3a402a6439c15c3d4294333e13042b915bbeab54edc457c723931fed3f/GitPython-3.1.43-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for pydeck<1,>=0.8.0b4 from https://files.pythonhosted.org/packages/ab/4c/b888e6cf58bd9db9c93f40d1c6be8283ff49d88919231afe93a6bcf61626/pydeck-0.9.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (6.3.2)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 4)) (2.1.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from langchain_community->-r requirements.txt (line 5)) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from langchain_community->-r requirements.txt (line 5)) (3.8.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/92/70/382283d80cb998ebc0089428b109bbe606ec9dce891a3cb1468c03ed0ad6/dataclasses_json-0.6.6-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.0 (from langchain_community->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for langchain<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/ff/39/62b8d2eb468a3b924c6bd1e411ef969c340130f4833abee35c15f0df421b/langchain-0.2.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting httpx>=0.23.0 (from langserve->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for httpx>=0.23.0 from https://files.pythonhosted.org/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting orjson>=2 (from langserve->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for orjson>=2 from https://files.pythonhosted.org/packages/f9/b7/3815984df03b677644c90cd4893d6293c80ef1c9f3a8493807bc1eb47da7/orjson-3.10.3-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading orjson-3.10.3-cp311-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.9/50.9 kB ? eta 0:00:00\n",
      "Collecting pyproject-toml<0.0.11,>=0.0.10 (from langserve->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for pyproject-toml<0.0.11,>=0.0.10 from https://files.pythonhosted.org/packages/3b/56/95d700e725946200ec9b2aeee4479fcf3ca24cf6fbf0aa548160980787a5/pyproject_toml-0.0.10-py3-none-any.whl.metadata\n",
      "  Downloading pyproject_toml-0.0.10-py3-none-any.whl.metadata (642 bytes)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for starlette<0.38.0,>=0.37.2 from https://files.pythonhosted.org/packages/fd/18/31fa32ed6c68ba66220204ef0be798c349d0a20c1901f9d4a794e08c76d8/starlette-0.37.2-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for fastapi-cli>=0.0.2 from https://files.pythonhosted.org/packages/a1/03/89bf615052aa5453c04d952225ded0b88aab6487b9c5f0c268939d13b860/fastapi_cli-0.0.4-py3-none-any.whl.metadata\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from fastapi->-r requirements.txt (line 7)) (3.1.2)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for python-multipart>=0.0.7 from https://files.pythonhosted.org/packages/3d/47/444768600d9e0ebc82f8e347775d24aef8f6348cf00e9fa0e81910814e6d/python_multipart-0.0.9-py3-none-any.whl.metadata\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from fastapi->-r requirements.txt (line 7)) (5.4.0)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for email_validator>=2.0.0 from https://files.pythonhosted.org/packages/e4/60/b02cb0f5ee0be88bd4fbfdd9cc91e43ec2dfcc47fe064e7c70587ff58a94/email_validator-2.1.1-py3-none-any.whl.metadata\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for h11>=0.8 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from sse_starlette->-r requirements.txt (line 9)) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq->-r requirements.txt (line 13))\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from groq->-r requirements.txt (line 13)) (1.2.0)\n",
      "Collecting cassandra-driver<4.0.0,>=3.28.0 (from cassio->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for cassandra-driver<4.0.0,>=3.28.0 from https://files.pythonhosted.org/packages/e0/2b/ea4a9c178de54f790acd2949650121490a6b98fc29bf8926ce11596eeb36/cassandra_driver-3.29.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cassandra_driver-3.29.1-cp311-cp311-win_amd64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 15)) (2.4)\n",
      "Collecting feedparser==6.0.10 (from arxiv->-r requirements.txt (line 18))\n",
      "  Obtaining dependency information for feedparser==6.0.10 from https://files.pythonhosted.org/packages/92/1e/741fd94cf2855d251712868f2183cb6485a28daaa3947e1a7046dc036aca/feedparser-6.0.10-py3-none-any.whl.metadata\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sgmllib3k (from feedparser==6.0.10->arxiv->-r requirements.txt (line 18))\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 4)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 4)) (2024.2.2)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub->-r requirements.txt (line 19))\n",
      "  Obtaining dependency information for types-requests<3.0.0.0,>=2.31.0.2 from https://files.pythonhosted.org/packages/cf/12/41212fac764c538e9472c7abccf40db3d9d9a40658184388f9dbb78dc6e1/types_requests-2.32.0.20240523-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.32.0.20240523-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting transformers (from -r requirements.txt (line 25))\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/79/e1/dcba5ba74392015ceeababf3455138f5875202e66e3316d7ca223bdb7b1c/transformers-4.41.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.8/43.8 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from sentence_transformers->-r requirements.txt (line 20)) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from sentence_transformers->-r requirements.txt (line 20)) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from sentence_transformers->-r requirements.txt (line 20)) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from sentence_transformers->-r requirements.txt (line 20)) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from sentence_transformers->-r requirements.txt (line 20)) (0.22.2)\n",
      "INFO: pip is looking at multiple versions of langchain-objectbox to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-groq (from -r requirements.txt (line 16))\n",
      "  Obtaining dependency information for langchain-groq from https://files.pythonhosted.org/packages/ef/08/2c1c4b0616e8f74e4e7574695f76d0ab875f8418bf5244f9870afb1b18ff/langchain_groq-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading langchain_groq-0.1.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for langchain-groq from https://files.pythonhosted.org/packages/f5/17/892ee2ff1275fc3d0991e6aab744027d59825fc767b112260c7d343c0eab/langchain_groq-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_groq-0.1.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Obtaining dependency information for langchain-groq from https://files.pythonhosted.org/packages/61/74/009e592467676013228f439edba4e6eebd51bfe34f8a0b15ee7400ee1db9/langchain_groq-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_groq-0.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Obtaining dependency information for langchain-groq from https://files.pythonhosted.org/packages/c9/73/8c3ff56c2ab0f5342568120f36e1582467b3bdf1ba53fbec34e96eab592f/langchain_groq-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain_groq-0.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Obtaining dependency information for langchain-groq from https://files.pythonhosted.org/packages/c1/46/dbf0cd0d85741fab452177a564c86549e15949f02315c973dd8f03f49579/langchain_groq-0.0.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_groq-0.0.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langserve (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for langserve from https://files.pythonhosted.org/packages/37/1d/16f5fab50f4126c190d8afc1ee87510185639d792f72662d76c839fecb9e/langserve-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading langserve-0.2.0-py3-none-any.whl.metadata (39 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for langserve from https://files.pythonhosted.org/packages/18/0d/4477d5fec68ffcc53c7b7f2d403c3e4eb7698b9335ef1325e9d6910e1e8e/langserve-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading langserve-0.1.1-py3-none-any.whl.metadata (39 kB)\n",
      "INFO: pip is looking at multiple versions of langserve to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for langserve from https://files.pythonhosted.org/packages/17/a4/797d5bcb06edaab1932272d2ca0e162a25f1d9500d91792c49e46a3ad1f8/langserve-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading langserve-0.1.0-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.3/43.3 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for langserve from https://files.pythonhosted.org/packages/b3/49/5b407071f7ea5a861b3f4c3ed2f034cdafb75db1554bbe1a256a092d2669/langserve-0.0.51-py3-none-any.whl.metadata\n",
      "  Downloading langserve-0.0.51-py3-none-any.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.7/42.7 kB ? eta 0:00:00\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain_community (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/1b/ad/59d9f88057c29d0a5d9ed786358bbbc8797bda347f3f007d51a651d2613a/langchain_community-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/1b/d3/1f4d1941ae5a627299c8ea052847b99ad6674b97b699d8a08fc4faf25d3e/langchain_community-0.0.38-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/4a/d3/c3c1d4fc775551d18fbc3d62ae2cac7cb4c56614532a3e492a799d597b57/langchain_community-0.0.37-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/ef/20/df5eb4eaf6a027fb185ac97720f5d365d11c972a122bb9fa2ba8a435b8ea/langchain_community-0.0.36-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/b4/9a/ace5461a52b173bed9955bc828142d30506d2a944d1882a44a7fadea8a4c/langchain_community-0.0.35-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/0a/48/40d8863d18160f3d148d173db3180b0a558525562e9c5ab8c2a338684919/langchain_community-0.0.34-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/1f/cc/f65b573144bc95044354228760138a158dc09856beab8d178130591b2694/langchain_community-0.0.33-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/6d/9e/2af18bcaebd47995ec5a4e3eeb7c6cf8e6a99c637a7cafe09bb98fc0f6f5/langchain_community-0.0.32-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/8a/67/6855b4a55e4e150264fd1a51888d20a1ba3c1b7757660f7ec4a14bd3d7a0/langchain_community-0.0.31-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/94/c9/7d8c1dca1715059427b5cb02fdce37b2705ca9f04e9dac125c0d4f6d0909/langchain_community-0.0.30-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/e1/80/4136757bf245f60e2f4e148adb340207ea330be92bc26727bca32fe6bc48/langchain_community-0.0.29-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/f9/c5/40e0fa5fddce3028052d6ae9596c5629dd6f81176c78e229c58e58409f55/langchain_community-0.0.28-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/8d/cc/387b93205020d23151c039e73805062c749a452a417fc578c7ea69efd469/langchain_community-0.0.27-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/a1/57/38a7fabcc9652c1aa7448b6679c297aba5fe21e5c49849cd008b9a8710d2/langchain_community-0.0.26-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/b6/23/ceba35a18190531e3f13d12a71480efe0744a0b8420e3ea570b69ba2f381/langchain_community-0.0.25-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/95/c4/cb370b12b8e43bd23976acab001e2b3ae2aeae501d012e3fb3043a380e12/langchain_community-0.0.24-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/7a/1a/0c5c7f50ec790b9ecb8e90b2b8fa339fe156b74202849cf78885bfd71a16/langchain_community-0.0.23-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/ae/98/3066c36e74f916ccb875afa40d9a4cee28755335ce7b6c675c25d4572920/langchain_community-0.0.22-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/2f/39/e4998914febe29c91953ab8c50fe793ca6e2780f4744e92a83ad261bf637/langchain_community-0.0.21-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/44/21/0c26e7f4cbea8ecc22c21dda8cca29a378b9d2795aebaa47ed40b130979d/langchain_community-0.0.20-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/bf/b4/1b1b22ab0c57320c5476b735cfe1500e49ddc4425df9e4c2e569e4c4472e/langchain_community-0.0.19-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/be/a4/180f33942fcf23e26853a1ff46245ede0acbf911b490339f0700a734b364/langchain_community-0.0.18-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.18-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/73/b3/f0096f0e040a8ecdcf5d0cd1a6ad8bef30e293fa7a7fcd25a752776bce78/langchain_community-0.0.17-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.17-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/57/00/a798f8124db57eb9e20fe31dc7561e15e9c4607281cddaa4db49f93d7111/langchain_community-0.0.16-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.16-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/5e/fe/772dd89e3d823bb944bc6428674544dd761ac667eda4c13ec94d1ebc3d05/langchain_community-0.0.15-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.15-py3-none-any.whl.metadata (7.6 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/af/e5/717f5476592529d0d90fb05557349b3320ba7b78763a6e4306c45a071fd8/langchain_community-0.0.14-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.14-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/2a/24/224115d2666ff3ff4917f2ebc98b9da2d2fe8835ec57909ceca5972a117e/langchain_community-0.0.13-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.13-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/80/18/33bf210e5410289b76da2862e6bcaf2217ee8c42ed0857e02741c4c02431/langchain_community-0.0.12-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/82/f5/9ae4e971ce553e20aae597df39806ed8d862e8536bd80a11497bebe1262a/langchain_community-0.0.11-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.11-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/3b/db/ce4a9244a6a2d9fc07394f94fe4c7041a478cc14e03072f9e8bbece92667/langchain_community-0.0.10-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.10-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/2f/91/0f9ce51f60f5e35fff85a094f0254f22e1645bd4fcfb69fe0cab1b1bc5ea/langchain_community-0.0.8-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.8-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/81/ac/4002f920066d13c50d93c3745f8a96c744a9413d2edefbf021dff0e8dcee/langchain_community-0.0.7-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/bc/69/b97f59cfe0ea85736e0ad0f5c41f37ab713ed1e576e468d72267a1da3d40/langchain_community-0.0.6-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.6-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/73/74/01a2c5c1efc033114f24d478650a973121ce72a3b47bc3c2438910ec68a8/langchain_community-0.0.5-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/74/81/e8ce34fe95eab1720510ccf85c81488bdd3fb8faca2d65685a040c44053b/langchain_community-0.0.4-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/f2/46/060f2f56d03a4db099ec9213e58ec971aec5d6922e5e16e8f29e840c1505/langchain_community-0.0.3-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/69/38/196c246cb7508a415936b43513bc7a7e12cefd24add4c34dab75d66146b3/langchain_community-0.0.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Obtaining dependency information for langchain_community from https://files.pythonhosted.org/packages/3e/73/2c1d5859d918b7a47c72f35dc407930f1f9754f9063cdfa29061b118ccbb/langchain_community-0.0.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain_openai (from -r requirements.txt (line 1))\n",
      "  Obtaining dependency information for langchain_openai from https://files.pythonhosted.org/packages/10/27/43f785670a340363fe46e2893a80293fa12448584f19ba4f9e6d03673552/langchain_openai-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-objectbox to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is still looking at multiple versions of langserve to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_core (from -r requirements.txt (line 2))\n",
      "  Obtaining dependency information for langchain_core from https://files.pythonhosted.org/packages/43/8b/48b7e6de9041d2b33d5108e154b82d1bd6c47cc68f0e44cb4fcdaccf5ec7/langchain_core-0.1.52-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting objectbox<5.0.0,>=4.0.0 (from langchain-objectbox->-r requirements.txt (line 22))\n",
      "  Obtaining dependency information for objectbox<5.0.0,>=4.0.0 from https://files.pythonhosted.org/packages/a2/b9/09f6521a35842542fe889a357722a35ff81ddcbed48ac9c086d996bec50b/objectbox-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading objectbox-4.0.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from pyopenssl->-r requirements.txt (line 24)) (41.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 25)) (3.9.0)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence_transformers->-r requirements.txt (line 20))\n",
      "  Obtaining dependency information for huggingface-hub>=0.15.1 from https://files.pythonhosted.org/packages/78/71/6ce4136149cb42b98599d49c39b3a39dd6858b5f9307490998c40e26a51e/huggingface_hub-0.23.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 25)) (2022.7.9)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers->-r requirements.txt (line 25))\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/65/8e/6d7d72b28f22c422cff8beae10ac3c2e4376b9be721ef8167b7eecd1da62/tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers->-r requirements.txt (line 25))\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/cb/f6/19f268662be898ff2a23ac06f8dd0d2956b2ecd204c96e1ee07ba292c119/safetensors-0.4.3-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 5)) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 5)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 5)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 4)) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 4)) (0.12.0)\n",
      "Collecting geomet<0.3,>=0.1 (from cassandra-driver<4.0.0,>=3.28.0->cassio->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for geomet<0.3,>=0.1 from https://files.pythonhosted.org/packages/c9/81/156ca48f950f833ddc392f8e3677ca50a18cb9d5db38ccb4ecea55a9303f/geomet-0.2.1.post1-py3-none-any.whl.metadata\n",
      "  Downloading geomet-0.2.1.post1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit->-r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl->-r requirements.txt (line 24)) (1.15.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/be/24/cbb242420021a79c87768dcd22ce028f48ef40913239ad6106c8a557f52c/marshmallow-3.21.2-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/87/a1/8c5287991ddb8d3e4662f71356d9656d91ab3a36618c3dd11b280df0d255/dnspython-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for typer>=0.12.3 from https://files.pythonhosted.org/packages/20/b5/11cf2e34fbb11b937e006286ab5b8cfd334fde1c8fa4dd7f491226931180/typer-0.12.3-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->langserve->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/78/d4/e5d7e4f2174f8a4d63c8897d79eb8fe2503f7ecc03282fee1fa2719c2704/httpcore-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers->-r requirements.txt (line 20)) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from jinja2>=2.11.2->fastapi->-r requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r requirements.txt (line 2)) (2.1)\n",
      "Requirement already satisfied: flatbuffers==24.3.25 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from objectbox<5.0.0,>=4.0.0->langchain-objectbox->-r requirements.txt (line 22)) (24.3.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 4)) (2022.7)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain_core->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.3 (from pydantic<3,>=1->langchain_core->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for pydantic-core==2.18.3 from https://files.pythonhosted.org/packages/d2/c7/e01cb2017c4b7b274258694f73e8bbbb0988a28b49802e569d1d9bfd51cb/pydantic_core-2.18.3-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.18.3-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: setuptools>=42 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from pyproject-toml<0.0.11,>=0.0.10->langserve->-r requirements.txt (line 6)) (68.0.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from pyproject-toml<0.0.11,>=0.0.10->langserve->-r requirements.txt (line 6)) (0.38.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 4)) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community->-r requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 20)) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 20)) (3.1)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/14/e4/20d28dfe7f5b5603b6b04c33bb88662ad749de51f0c539a561f235f42666/httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/2b/8b/93f4e3ed0d578676b3c2e9d4ebf0b51237f4a96bbe3830b146662cb249da/watchfiles-0.22.0-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading watchfiles-0.22.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for websockets>=10.4 from https://files.pythonhosted.org/packages/d1/40/6b169cd1957476374f51f4486a3e85003149e62a14e6b78a958c2222337a/websockets-12.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 20)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 20)) (2.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl->-r requirements.txt (line 24)) (2.21)\n",
      "Requirement already satisfied: six in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio->-r requirements.txt (line 14)) (1.16.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 4)) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->-r requirements.txt (line 7)) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kvsns\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 20)) (1.3.0)\n",
      "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.0 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 16.1 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 302.9/302.9 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading langchain_groq-0.1.4-py3-none-any.whl (11 kB)\n",
      "Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
      "   ---------------------------------------- 0.0/8.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.6 MB 14.2 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.9/8.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.6/8.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.4/8.6 MB 14.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.1/8.6 MB 14.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.8/8.6 MB 14.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.7/8.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.5/8.6 MB 15.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.3/8.6 MB 15.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.2/8.6 MB 15.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.1/8.6 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.6/8.6 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.6/8.6 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading langserve-0.2.1-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 0.9/1.2 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 18.4 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/92.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 92.0/92.0 kB ? eta 0:00:00\n",
      "Downloading uvicorn-0.30.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.4/62.4 kB ? eta 0:00:00\n",
      "Downloading sse_starlette-2.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 290.4/290.4 kB 18.7 MB/s eta 0:00:00\n",
      "Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.7/14.5 MB 14.8 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.2/14.5 MB 13.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.3/14.5 MB 12.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.4/14.5 MB 8.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.7/14.5 MB 7.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.1/14.5 MB 7.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.6/14.5 MB 8.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.2/14.5 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.8/14.5 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.3/14.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.9/14.5 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.7/14.5 MB 11.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.3/14.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.1/14.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.7/14.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.3/14.5 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.8/14.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.4/14.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.2/14.5 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.8/14.5 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.5/14.5 MB 13.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.5 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading groq-0.8.0-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.4/105.4 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading cassio-0.1.7-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB ? eta 0:00:00\n",
      "Downloading arxiv-2.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "   ---------------------------------------- 0.0/81.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 81.1/81.1 kB ? eta 0:00:00\n",
      "Downloading langchainhub-0.1.17-py3-none-any.whl (4.8 kB)\n",
      "Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n",
      "   ---------------------------------------- 0.0/224.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 224.7/224.7 kB 13.4 MB/s eta 0:00:00\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 232.6/232.6 kB 13.9 MB/s eta 0:00:00\n",
      "Downloading langchain_objectbox-0.1.0-py3-none-any.whl (7.2 kB)\n",
      "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/9.1 MB 18.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.4/9.1 MB 18.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.2/9.1 MB 17.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.9/9.1 MB 18.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.5/9.1 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.2/9.1 MB 17.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.1/9.1 MB 16.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.9/9.1 MB 17.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/9.1 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.6/9.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.5/9.1 MB 17.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.1 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 16.1 MB/s eta 0:00:00\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "   ---------------------------------------- 0.0/857.8 kB ? eta -:--:--\n",
      "   -------------------------------- ------ 716.8/857.8 kB 22.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 857.8/857.8 kB 18.4 MB/s eta 0:00:00\n",
      "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading cassandra_driver-3.29.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 16.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.0/2.7 MB 16.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/207.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 207.3/207.3 kB ? eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB ? eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 401.7/401.7 kB 24.5 MB/s eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.63-py3-none-any.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.8/122.8 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading objectbox-4.0.0-py3-none-any.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.0 MB 31.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.6/4.0 MB 20.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.3/4.0 MB 18.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.7/4.0 MB 15.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.2/4.0 MB 14.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.9/4.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading openai-1.30.4-py3-none-any.whl (320 kB)\n",
      "   ---------------------------------------- 0.0/320.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 320.6/320.6 kB 20.7 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.3-cp311-none-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.8/138.8 kB 8.0 MB/s eta 0:00:00\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading pydantic-2.7.2-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 409.5/409.5 kB 12.9 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.3-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.9/1.9 MB 18.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 15.0 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.7/6.9 MB 15.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.5/6.9 MB 16.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.4/6.9 MB 17.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.3/6.9 MB 17.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/6.9 MB 18.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.3/6.9 MB 18.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.2/6.9 MB 20.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.9/6.9 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 17.7 MB/s eta 0:00:00\n",
      "Downloading pyproject_toml-0.0.10-py3-none-any.whl (6.9 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 287.3/287.3 kB 18.5 MB/s eta 0:00:00\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-win_amd64.whl (799 kB)\n",
      "   ---------------------------------------- 0.0/799.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 799.0/799.0 kB 16.8 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.2 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.2 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 15.7 MB/s eta 0:00:00\n",
      "Downloading types_requests-2.32.0.20240523-py3-none-any.whl (15 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 307.7/307.7 kB 19.8 MB/s eta 0:00:00\n",
      "Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.4/55.4 kB ? eta 0:00:00\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB ? eta 0:00:00\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.2/47.2 kB ? eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.1/121.1 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp311-none-win_amd64.whl (281 kB)\n",
      "   ---------------------------------------- 0.0/282.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 282.0/282.0 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB ? eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: wikipedia, sgmllib3k\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11707 sha256=09d074cf3bb7f925786ade622355cef7277f4f273531ecf03b7bca6c495709ff\n",
      "  Stored in directory: c:\\users\\kvsns\\appdata\\local\\pip\\cache\\wheels\\8f\\ab\\cb\\45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6061 sha256=2258794c86d527486a8ad1219a3702176a0d54ca213ee81818a10128ff9b665c\n",
      "  Stored in directory: c:\\users\\kvsns\\appdata\\local\\pip\\cache\\wheels\\3b\\25\\2a\\105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built wikipedia sgmllib3k\n",
      "Installing collected packages: sgmllib3k, websockets, urllib3, typing-inspect, smmap, safetensors, python-multipart, PyPDF2, pypdf, pydantic-core, packaging, orjson, objectbox, jsonpatch, httptools, h11, feedparser, faiss-cpu, dnspython, distro, blinker, annotated-types, watchfiles, uvicorn, types-requests, starlette, pyproject-toml, pydeck, pydantic, marshmallow, httpcore, gitdb, geomet, email_validator, bs4, wikipedia, typer, tiktoken, sse_starlette, langsmith, langchainhub, huggingface-hub, httpx, gitpython, dataclasses-json, cassandra-driver, arxiv, altair, tokenizers, streamlit, openai, langchain_core, groq, fastapi-cli, cassio, transformers, langserve, langchain_openai, langchain-objectbox, langchain-groq, langchain_community, fastapi, sentence_transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.12.0\n",
      "    Uninstalling typer-0.12.0:\n",
      "      Successfully uninstalled typer-0.12.0\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.6.0\n",
      "    Uninstalling tiktoken-0.6.0:\n",
      "      Successfully uninstalled tiktoken-0.6.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.22.2\n",
      "    Uninstalling huggingface-hub-0.22.2:\n",
      "      Successfully uninstalled huggingface-hub-0.22.2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.1.1\n",
      "    Uninstalling transformers-2.1.1:\n",
      "      Successfully uninstalled transformers-2.1.1\n",
      "Successfully installed PyPDF2-3.0.1 altair-5.3.0 annotated-types-0.7.0 arxiv-2.1.0 blinker-1.8.2 bs4-0.0.2 cassandra-driver-3.29.1 cassio-0.1.7 dataclasses-json-0.6.6 distro-1.9.0 dnspython-2.6.1 email_validator-2.1.1 faiss-cpu-1.8.0 fastapi-0.111.0 fastapi-cli-0.0.4 feedparser-6.0.10 geomet-0.2.1.post1 gitdb-4.0.11 gitpython-3.1.43 groq-0.8.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.2 jsonpatch-1.33 langchain-groq-0.1.4 langchain-objectbox-0.1.0 langchain_community-0.0.38 langchain_core-0.1.52 langchain_openai-0.1.7 langchainhub-0.1.17 langserve-0.2.1 langsmith-0.1.63 marshmallow-3.21.2 objectbox-4.0.0 openai-1.30.4 orjson-3.10.3 packaging-23.2 pydantic-2.7.2 pydantic-core-2.18.3 pydeck-0.9.1 pypdf-4.2.0 pyproject-toml-0.0.10 python-multipart-0.0.9 safetensors-0.4.3 sentence_transformers-3.0.0 sgmllib3k-1.0.0 smmap-5.0.1 sse_starlette-2.1.0 starlette-0.37.2 streamlit-1.35.0 tiktoken-0.7.0 tokenizers-0.19.1 transformers-4.41.1 typer-0.12.3 types-requests-2.32.0.20240523 typing-inspect-0.9.0 urllib3-2.2.1 uvicorn-0.30.0 watchfiles-0.22.0 websockets-12.0 wikipedia-1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "botocore 1.27.59 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.1 which is incompatible.\n",
      "conda 23.7.2 requires ruamel-yaml<0.18,>=0.11.14, but you have ruamel-yaml 0.18.6 which is incompatible.\n",
      "faster-whisper 1.0.0 requires tokenizers<0.16,>=0.13, but you have tokenizers 0.19.1 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "## RAG Application With GPT-4o\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get a Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"\\n\\n\\n\\n\\nLangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookThis is outdated documentation for ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith, which is no longer actively maintained.For up-to-date documentation, see the latest version.User GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.Prototypingâ€‹Prototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing â€” and debug where it is failing â€” is incredibly important for this phase.Debuggingâ€‹When developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isnâ€™t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), itâ€™s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Setâ€‹While many developers still ship an initial version of their application based on â€œvibe checksâ€�, weâ€™ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison Viewâ€‹When prototyping different versions of your applications and making changes, itâ€™s important to see whether or not youâ€™ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, itâ€™s useful to be able to view results for different configurations on the same datapoints side-by-side. Weâ€™ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playgroundâ€‹LangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testingâ€‹Beta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, itâ€™s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly itâ€™s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedbackâ€‹When launching your application to an initial set of users, itâ€™s important to gather human feedback on the responses itâ€™s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Tracesâ€‹LangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Datasetâ€‹As your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Productionâ€‹Closely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows youâ€™ll also want to do once your app hits production.However, especially at the production stage, itâ€™s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testingâ€‹LangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period â€” this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automationsâ€‹Automations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threadsâ€‹Many LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.\\n\\n\\n\\n\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert data to Vector Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_objectbox.vectorstores import ObjectBox ##vector Database\n",
    "from langchain_openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookThis is outdated documentation for 🦜️🛠️ LangSmith, which is no longer actively maintained.For up-to-date documentation, see the latest version.User GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content=\"Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production.However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automations\\u200bAutomations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threads\\u200bMany LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ObjectBox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m----> 2\u001b[0m vector \u001b[38;5;241m=\u001b[39m ObjectBox\u001b[38;5;241m.\u001b[39mfrom_documents(documents, OpenAIEmbeddings(), embedding_dimensions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m768\u001b[39m)\n\u001b[0;32m      3\u001b[0m vector\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ObjectBox' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "vector = ObjectBox.from_documents(documents, OpenAIEmbeddings(), embedding_dimensions=768)\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make a RAG pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hub\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m## Calling Gpt-4o\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mpull(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrlm/rag-prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m prompt\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hub' is not defined"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\") ## Calling Gpt-4o\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vector.as_retriever(),\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Explain what is langsmith',\n",
       " 'result': 'LangSmith is a platform designed for the development, monitoring, and testing of LLM (Large Language Model) applications. It supports various stages of the application lifecycle, including prototyping, debugging, beta testing, and production. The platform offers tools for tracing, evaluation, feedback collection, A/B testing, and automations to ensure optimal performance and quality of LLM applications.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Explain what is langsmith\"\n",
    "result = qa_chain({\"query\": question })\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is a platform designed for the development, monitoring, and testing of LLM (Large Language Model) applications. It supports various stages of the application lifecycle, including prototyping, debugging, beta testing, and production. The platform offers tools for tracing, evaluation, feedback collection, A/B testing, and automations to ensure optimal performance and quality of LLM applications.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LangSmith is a platform designed for the development, monitoring, and '\n",
      " 'testing of LLM (Large Language Model) applications. It supports various '\n",
      " 'stages of the application lifecycle, including prototyping, debugging, beta '\n",
      " 'testing, and production. The platform offers tools for tracing, evaluation, '\n",
      " 'feedback collection, A/B testing, and automations to ensure optimal '\n",
      " 'performance and quality of LLM applications.')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=5)\n",
    "pp.pprint(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Explain Monitoring and A/B Testing in langsmith',\n",
       " 'result': 'LangSmith provides monitoring charts to track key metrics over time, allowing users to drill down into specific data points for debugging production issues. It also supports A/B testing by enabling tag and metadata grouping, which allows users to compare the performance of different versions of their applications side-by-side within each chart. This helps in evaluating changes in prompt, model, or retrieval strategy effectively.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Explain Monitoring and A/B Testing in langsmith\"\n",
    "result = qa_chain({\"query\": question })\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
